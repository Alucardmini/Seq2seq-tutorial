{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最后一关：\n",
    "## Encoder：多层双向lstm\n",
    "## Attention机制\n",
    "## decoder：动态实现bi-directional_dynamic_rnn\n",
    "### 基于tensorflow1.4 Seq2seq的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生10个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[8, 9, 2, 8, 5, 5]\n",
      "[5, 5, 4, 5, 5, 3, 2]\n",
      "[6, 8, 8, 9, 6, 2]\n",
      "[3, 2, 8, 7, 7, 5]\n",
      "[6, 2, 9, 3, 3, 8, 9]\n",
      "[7, 6, 9]\n",
      "[4, 4, 9, 4, 2, 4, 5]\n",
      "[3, 6, 4, 3, 3]\n",
      "[6, 6, 7, 7]\n",
      "[3, 3, 9, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib import seq2seq,rnn\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "encoder_hidden_units = 25\n",
    "\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.使用seq2seq库实现seq2seq模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(tf.int32, [None, None], name='encoder_inputs')\n",
    "    \n",
    "    encoder_inputs_length = tf.placeholder(tf.int32, [None], name='encoder_inputs_length')\n",
    "    \n",
    "    decoder_targets = tf.placeholder(tf.int32, [None, None], name='decoder_targets')\n",
    "    \n",
    "    \"\"\"\n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),dtype=tf.int32,name='decoder_inputs')\n",
    "    \n",
    "    #decoder_inputs_length和decoder_targets_length是一样的\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "    \"\"\"\n",
    "# 构建embedding矩阵,encoder和decoder公用该词向量矩阵\n",
    "embedding = tf.get_variable('embedding', [vocab_size,input_embedding_size])\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embedding,encoder_inputs)\n",
    "\n",
    "#fw_cell = bw_cell =  rnn.LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义encoder，两层双向lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_inputs=encoder_inputs_embedded\n",
    "for _ in range(2):\n",
    "    #为什么在这加个variable_scope,被逼的,tf在rnn_cell的__call__中非要搞一个命名空间检查\n",
    "    #恶心的很.如果不在这加的话,会报错的.\n",
    "    with tf.variable_scope(None, default_name=\"bidirectional-rnn\"):\n",
    "        rnn_cell_bw =  rnn_cell_fw = rnn.LSTMCell(encoder_hidden_units)\n",
    "        #rnn_cell_bw = rnn.LSTMCell(encoder_hidden_units)\n",
    "        #initial_state_fw = rnn_cell_fw.zero_state(batch_size, dtype=tf.float32)\n",
    "        #initial_state_bw = rnn_cell_bw.zero_state(batch_size, dtype=tf.float32)\n",
    "        ((encoder_fw_outputs,encoder_bw_outputs),(encoder_fw_final_state,encoder_bw_final_state))\\\n",
    "        = tf.nn.bidirectional_dynamic_rnn(cell_fw=rnn_cell_fw,\n",
    "                                              cell_bw=rnn_cell_bw, \n",
    "                                              inputs=_inputs, \n",
    "                                              sequence_length=encoder_inputs_length,\n",
    "                                              dtype=tf.float32)\n",
    "        _inputs = tf.concat((encoder_fw_outputs,encoder_bw_outputs), 2)\n",
    "#取最后一层的 final_state    \n",
    "encoder_final_state_h = tf.concat((encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "encoder_final_state_c = tf.concat((encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "encoder_final_state = rnn.LSTMStateTuple(c=encoder_final_state_c, h=encoder_final_state_h)\n",
    "encoder_final_output = _inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'concat:0' shape=(?, 50) dtype=float32>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional-rnn_1/concat:0' shape=(?, ?, 50) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.定义decoder 部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这里的Decoder中，每个输入除了上一个时间节点的输出以外，还有对应时间节点的Encoder的输出，以及attention的context。\n",
    "![seq2seq-feed-previous](figure/nct-seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用的Helper：\n",
    "\n",
    "    TrainingHelper：适用于训练的helper。\n",
    "    InferenceHelper：适用于测试的helper。\n",
    "    GreedyEmbeddingHelper：适用于测试中采用Greedy策略sample的helper。\n",
    "    CustomHelper：用户自定义的helper。\n",
    "这里着重介绍CustomHelper，要传入三个函数作为参数：\n",
    "    initialize_fn：返回finished，next_inputs。其中finished不是scala，是一个一维向量。这个函数即获取第一个时间节点的输入。\n",
    "    sample_fn：接收参数(time, outputs, state) 返回sample_ids。即，根据每个cell的输出，如何sample。\n",
    "    next_inputs_fn：接收参数(time, outputs, state, sample_ids) 返回 (finished, next_inputs, next_state)，根据上一个时刻的输出，决定下一个时刻的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 传给CustomHelper的三个函数\n",
    "decoder_lengths = encoder_inputs_length+3#这里设置decoder_lengths比encoder_inputs_length长3个\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embedding, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embedding, pad_time_slice)\n",
    "\n",
    "def initial_fn():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    #initial_input = tf.concat((sos_step_embedded, encoder_outputs[0]), 1)\n",
    "    initial_input = eos_step_embedded\n",
    "    return initial_elements_finished, initial_input\n",
    "\n",
    "def sample_fn(time, outputs, state):\n",
    "    # 选择logit最大的下标作为sample\n",
    "    prediction_id = tf.to_int32(tf.argmax(outputs, axis=1))\n",
    "    return prediction_id\n",
    "\n",
    "def next_inputs_fn(time, outputs, state, sample_ids):\n",
    "    # 上一个时间节点上的输出类别，获取embedding再作为下一个时间节点的输入\n",
    "    pred_embedding = tf.nn.embedding_lookup(embedding, sample_ids)\n",
    "    # 输入是h_i+o_{i-1}+c_i\n",
    "    #next_input = tf.concat((pred_embedding, encoder_final_output[time]), 1)\n",
    "    next_input = pred_embedding\n",
    "    elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n",
    "    all_finished = tf.reduce_all(elements_finished)  # -> boolean scalar\n",
    "    next_inputs = tf.cond(all_finished, lambda: pad_step_embedded, lambda: next_input)\n",
    "    next_state = state\n",
    "    return elements_finished, next_inputs, next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " my_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Attention机制\n",
    "![seq2seq-feed-previous](figure/Attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attention_mechanism = seq2seq.BahdanauAttention(num_units=2*encoder_hidden_units,\n",
    "                                                memory=encoder_final_output,\n",
    "                                                memory_sequence_length=encoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units * 2)\n",
    "decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                    decoder_cell, attention_mechanism, attention_layer_size=encoder_hidden_units)\n",
    "output_layer = tf.layers.Dense(vocab_size,kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "\n",
    "decoder_initial_state = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32).clone(\n",
    "                cell_state=encoder_final_state)\n",
    "training_decoder = seq2seq.BasicDecoder(cell=decoder_cell, helper=my_helper,\n",
    "                                                                   initial_state=decoder_initial_state,\n",
    "                                                                   output_layer=output_layer)\n",
    "max_target_sequence_length = tf.reduce_max(decoder_lengths, name='max_target_len')\n",
    "decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder=training_decoder,impute_finished=True,\n",
    "                                               maximum_iterations=max_target_sequence_length)\n",
    "decoder_logits_train = tf.identity(decoder_outputs.rnn_output)\n",
    "sample_id = decoder_outputs.sample_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义计算loss的mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<tf.Tensor 'Identity_1:0' shape=(10, ?, 10) dtype=float32>\n",
      "\t<tf.Tensor 'minibatch/decoder_targets:0' shape=(?, ?) dtype=int32>\n",
      "\t<tf.Tensor 'decoder_1/transpose_1:0' shape=(10, ?) dtype=int32>\n"
     ]
    }
   ],
   "source": [
    "mask = tf.sequence_mask(decoder_lengths,max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "print('\\t%s' % repr(decoder_logits_train))\n",
    "print('\\t%s' % repr(decoder_targets))\n",
    "print('\\t%s' % repr(sample_id))\n",
    "loss = seq2seq.sequence_loss(logits=decoder_logits_train,targets=decoder_targets, weights=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[6 4 3 8 6 7 2 6]\n",
      "encoder_inputs_length:\n",
      "8\n",
      "decoder_targets:\n",
      "[6 4 3 8 6 7 2 6 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS]+ [PAD] * 2 for sequence in batch]#decoder_lengths比encoder length长3\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,     \n",
    "    }\n",
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][0,:])\n",
    "print('encoder_inputs_length:')\n",
    "print(x[encoder_inputs_length][0])\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.29461669921875\n",
      "  sample 1:\n",
      "    input     > [5 5 9 4 6 4 4 5]\n",
      "    predicted > [3 3 2 3 2 1 0 0 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 9 7 4 6 7 9 3]\n",
      "    predicted > [0 0 0 0 0 1 0 0 0 1 0]\n",
      "  sample 3:\n",
      "    input     > [6 6 4 2 8 0 0 0]\n",
      "    predicted > [0 1 0 1 0 0 1 0 1 0 0]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 1.6221174001693726\n",
      "  sample 1:\n",
      "    input     > [3 4 5 2 0 0 0 0]\n",
      "    predicted > [3 3 3 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 8 4 9 6 0 0 0]\n",
      "    predicted > [3 3 3 3 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 4 2 8 0 0 0 0]\n",
      "    predicted > [3 3 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 1.388022780418396\n",
      "  sample 1:\n",
      "    input     > [9 5 3 3 4 3 0 0]\n",
      "    predicted > [3 3 3 3 3 3 1 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 6 2 0 0 0 0 0]\n",
      "    predicted > [6 2 6 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 4 9 6 8 0 0]\n",
      "    predicted > [3 3 3 3 3 4 1 0 0 0 0]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 1.270598292350769\n",
      "  sample 1:\n",
      "    input     > [2 8 7 0 0 0 0 0]\n",
      "    predicted > [7 7 7 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 7 3 0 0 0 0 0]\n",
      "    predicted > [3 7 1 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 3 8 0 0 0 0 0]\n",
      "    predicted > [3 8 8 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 1.1839914321899414\n",
      "  sample 1:\n",
      "    input     > [2 7 2 3 6 3 8 5]\n",
      "    predicted > [2 2 2 2 2 8 8 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 6 7 7 0 0 0 0]\n",
      "    predicted > [7 7 7 7 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 3 7 2 3 0 0 0]\n",
      "    predicted > [2 8 8 8 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 1.178087592124939\n",
      "  sample 1:\n",
      "    input     > [7 5 8 8 6 5 0 0]\n",
      "    predicted > [8 8 8 8 8 8 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 4 4 6 7 0 0]\n",
      "    predicted > [2 2 4 4 4 4 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 3 2 6 2 7 3 0]\n",
      "    predicted > [7 6 6 6 6 7 7 1 0 0 0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.895336925983429\n",
      "  sample 1:\n",
      "    input     > [8 7 7 4 0 0 0 0]\n",
      "    predicted > [7 7 7 7 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 9 9 7 6 8 2 0]\n",
      "    predicted > [3 3 7 7 7 7 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 7 2 0 0 0 0 0]\n",
      "    predicted > [2 2 2 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 0.29237034916877747\n",
      "  sample 1:\n",
      "    input     > [6 8 2 0 0 0 0 0]\n",
      "    predicted > [6 8 2 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 8 7 6 7 4 5 6]\n",
      "    predicted > [5 8 7 6 7 4 5 6 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 5 0 0 0 0 0]\n",
      "    predicted > [9 6 5 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.1250164806842804\n",
      "  sample 1:\n",
      "    input     > [6 7 3 7 5 9 6 8]\n",
      "    predicted > [6 7 3 7 5 9 6 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 7 7 0 0 0 0 0]\n",
      "    predicted > [9 7 7 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 3 4 7 4 8 0 0]\n",
      "    predicted > [7 3 4 7 4 8 1 0 0 0 0]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 0.04103495180606842\n",
      "  sample 1:\n",
      "    input     > [4 7 5 2 5 2 6 0]\n",
      "    predicted > [4 7 5 2 5 2 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 7 8 0 0 0 0 0]\n",
      "    predicted > [5 7 8 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 3 2 6 0 0 0 0]\n",
      "    predicted > [4 3 2 6 1 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.02061438001692295\n",
      "  sample 1:\n",
      "    input     > [5 9 9 6 4 6 9 0]\n",
      "    predicted > [5 9 9 6 4 6 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 7 7 2 3 9 0 0]\n",
      "    predicted > [3 7 7 2 3 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 4 6 8 7 6 3]\n",
      "    predicted > [4 2 4 6 8 7 6 3 1 0 0]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 0.018973074853420258\n",
      "  sample 1:\n",
      "    input     > [5 3 9 5 7 2 5 6]\n",
      "    predicted > [5 3 9 5 7 2 5 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 7 4 8 8 9 0 0]\n",
      "    predicted > [2 7 4 8 8 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 8 3 7 5 0 0 0]\n",
      "    predicted > [3 8 3 7 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 0.01220142375677824\n",
      "  sample 1:\n",
      "    input     > [6 8 7 0 0 0 0 0]\n",
      "    predicted > [6 8 7 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 6 6 0 0 0 0 0]\n",
      "    predicted > [5 6 6 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 5 4 0 0 0 0 0]\n",
      "    predicted > [6 5 4 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 0.008632375858724117\n",
      "  sample 1:\n",
      "    input     > [8 9 3 4 9 2 0 0]\n",
      "    predicted > [8 9 3 4 9 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 9 2 4 7 9 3 0]\n",
      "    predicted > [5 9 2 4 7 9 3 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 6 6 0 0 0 0 0]\n",
      "    predicted > [5 6 6 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.00644361088052392\n",
      "  sample 1:\n",
      "    input     > [8 2 8 7 0 0 0 0]\n",
      "    predicted > [8 2 8 7 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 5 9 0 0 0 0 0]\n",
      "    predicted > [9 5 9 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 5 6 9 4 6 8 4]\n",
      "    predicted > [6 5 6 9 4 6 8 4 1 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.005314035806804895\n",
      "  sample 1:\n",
      "    input     > [7 2 5 9 8 4 4 0]\n",
      "    predicted > [7 2 5 9 8 4 4 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 9 9 4 3 0 0 0]\n",
      "    predicted > [4 9 9 4 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 6 4 5 8 0 0 0]\n",
      "    predicted > [8 6 4 5 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.005184624344110489\n",
      "  sample 1:\n",
      "    input     > [3 4 2 0 0 0 0 0]\n",
      "    predicted > [3 4 2 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 8 5 3 5 3 0 0]\n",
      "    predicted > [6 8 5 3 5 3 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 2 4 8 8 0 0 0]\n",
      "    predicted > [9 2 4 8 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 0.0034769047051668167\n",
      "  sample 1:\n",
      "    input     > [8 5 8 7 4 9 9]\n",
      "    predicted > [8 5 8 7 4 9 9 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 5 8 0 0 0 0]\n",
      "    predicted > [3 5 8 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 7 5 2 7 0]\n",
      "    predicted > [4 4 7 5 2 7 1 0 0 0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.002784730400890112\n",
      "  sample 1:\n",
      "    input     > [2 5 7 4 0 0 0 0]\n",
      "    predicted > [2 5 7 4 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 7 2 5 0 0 0]\n",
      "    predicted > [5 4 7 2 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 9 5 4 5 4 0 0]\n",
      "    predicted > [4 9 5 4 5 4 1 0 0 0 0]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 0.002491097431629896\n",
      "  sample 1:\n",
      "    input     > [4 9 9 5 9 0 0 0]\n",
      "    predicted > [4 9 9 5 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 2 4 9 7 2 8 9]\n",
      "    predicted > [2 2 4 9 7 2 8 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 8 8 2 4 0 0 0]\n",
      "    predicted > [9 8 8 2 4 1 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.0022913815919309855\n",
      "  sample 1:\n",
      "    input     > [3 4 9 4 5 6 0 0]\n",
      "    predicted > [3 4 9 4 5 6 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 4 4 6 0 0 0]\n",
      "    predicted > [2 8 4 4 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 5 8 7 0 0 0]\n",
      "    predicted > [2 9 5 8 7 1 0 0 0 0 0]\n",
      "\n",
      "batch 2100\n",
      "  minibatch loss: 0.001817821292206645\n",
      "  sample 1:\n",
      "    input     > [8 3 6 2 0 0 0 0]\n",
      "    predicted > [8 3 6 2 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 8 6 2 0 0 0 0]\n",
      "    predicted > [4 8 6 2 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 2 5 6 9 3 4 0]\n",
      "    predicted > [8 2 5 6 9 3 4 1 0 0 0]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 0.0017419641371816397\n",
      "  sample 1:\n",
      "    input     > [2 2 3 0 0 0 0 0]\n",
      "    predicted > [2 2 3 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 5 3 8 2 4 0 0]\n",
      "    predicted > [7 5 3 8 2 4 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 2 7 3 4 6 4 8]\n",
      "    predicted > [8 2 7 3 4 6 4 8 1 0 0]\n",
      "\n",
      "batch 2300\n",
      "  minibatch loss: 0.001424401649273932\n",
      "  sample 1:\n",
      "    input     > [5 3 5 4 8 3 8 8]\n",
      "    predicted > [5 3 5 4 8 3 8 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 4 7 9 5 0 0 0]\n",
      "    predicted > [3 4 7 9 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 8 9 0 0 0 0 0]\n",
      "    predicted > [8 8 9 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 0.0014329373370856047\n",
      "  sample 1:\n",
      "    input     > [6 6 2 8 7 0 0 0]\n",
      "    predicted > [6 6 2 8 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 4 5 5 0 0 0 0]\n",
      "    predicted > [7 4 5 5 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 9 5 9 6 6 7 6]\n",
      "    predicted > [8 9 5 9 6 6 7 6 1 0 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 0.001270524924620986\n",
      "  sample 1:\n",
      "    input     > [7 7 8 9 7 9 9 5]\n",
      "    predicted > [7 7 8 9 7 9 9 5 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 8 4 0 0 0 0 0]\n",
      "    predicted > [6 8 4 1 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 7 3 2 0 0 0]\n",
      "    predicted > [8 5 7 3 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 0.0008346579852513969\n",
      "  sample 1:\n",
      "    input     > [6 6 8 5 0 0 0]\n",
      "    predicted > [6 6 8 5 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 7 3 4 9 2 9]\n",
      "    predicted > [5 7 3 4 9 2 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 2 4 3 0 0 0]\n",
      "    predicted > [7 2 4 3 1 0 0 0 0 0]\n",
      "\n",
      "batch 2700\n",
      "  minibatch loss: 0.0009551114053465426\n",
      "  sample 1:\n",
      "    input     > [4 8 4 4 3 8 5 8]\n",
      "    predicted > [4 8 4 4 3 8 5 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 8 8 0 0 0 0]\n",
      "    predicted > [2 3 8 8 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 5 8 7 6 3 0]\n",
      "    predicted > [2 9 5 8 7 6 3 1 0 0 0]\n",
      "\n",
      "batch 2800\n",
      "  minibatch loss: 0.000799523142632097\n",
      "  sample 1:\n",
      "    input     > [3 8 8 0 0 0 0 0]\n",
      "    predicted > [3 8 8 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 4 8 5 0 0 0 0]\n",
      "    predicted > [2 4 8 5 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 6 7 0 0 0 0 0]\n",
      "    predicted > [6 6 7 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2900\n",
      "  minibatch loss: 0.000805568415671587\n",
      "  sample 1:\n",
      "    input     > [9 7 6 4 8 6 4 0]\n",
      "    predicted > [9 7 6 4 8 6 4 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 8 3 3 8 2 6 9]\n",
      "    predicted > [8 8 3 3 8 2 6 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 7 3 8 5 9 4 0]\n",
      "    predicted > [8 7 3 8 5 9 4 1 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.000771542196162045\n",
      "  sample 1:\n",
      "    input     > [7 3 3 0 0 0 0 0]\n",
      "    predicted > [7 3 3 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 4 4 4 7 7 0 0]\n",
      "    predicted > [8 4 4 4 7 7 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 7 5 9 3 6 0]\n",
      "    predicted > [2 8 7 5 9 3 6 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 100\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_outputs.sample_id, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
