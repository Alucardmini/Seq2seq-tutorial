{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现beam_search部分\n",
    "### 基于tensorflow1.4 Seq2seq的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生10个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[8, 2, 7, 2]\n",
      "[6, 7, 9, 2, 5, 3]\n",
      "[3, 7, 5, 3, 2, 3, 4]\n",
      "[7, 4, 6, 4, 2]\n",
      "[9, 5, 5, 5, 7, 8]\n",
      "[8, 7, 7, 6, 8, 6, 2]\n",
      "[9, 6, 3, 5, 3, 8, 5, 4]\n",
      "[7, 8, 4, 8]\n",
      "[7, 8, 7, 5, 4]\n",
      "[4, 7, 9, 4, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.contrib import seq2seq,rnn\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "encoder_hidden_units = 25\n",
    "\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.使用seq2seq库实现seq2seq模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 计算图的数据的placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(tf.int32, [None, None], name='encoder_inputs')\n",
    "    \n",
    "    encoder_inputs_length = tf.placeholder(tf.int32, [None], name='encoder_inputs_length')\n",
    "    \n",
    "    decoder_targets = tf.placeholder(tf.int32, [None, None], name='decoder_targets')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),dtype=tf.int32,name='decoder_inputs')\n",
    "    \n",
    "    #decoder_inputs_length和decoder_targets_length是一样的\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _create_rnn_cell():\n",
    "    def single_rnn_cell(encoder_hidden_units):\n",
    "        # 创建单个cell，这里需要注意的是一定要使用一个single_rnn_cell的函数，不然直接把cell放在MultiRNNCell\n",
    "        # 的列表中最终模型会发生错误\n",
    "        single_cell = rnn.LSTMCell(encoder_hidden_units)\n",
    "        #添加dropout\n",
    "        single_cell = rnn.DropoutWrapper(single_cell, output_keep_prob=0.5)\n",
    "        return single_cell\n",
    "            #列表中每个元素都是调用single_rnn_cell函数\n",
    "            #cell = rnn.MultiRNNCell([single_rnn_cell() for _ in range(self.num_layers)])\n",
    "    cell = rnn.MultiRNNCell([single_rnn_cell(encoder_hidden_units) for _ in range(1)])\n",
    "    return cell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义encoder 部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('encoder'):\n",
    "    # 创建LSTMCell\n",
    "    encoder_cell = _create_rnn_cell()\n",
    "    # 构建embedding矩阵,encoder和decoder公用该词向量矩阵\n",
    "    embedding = tf.get_variable('embedding', [vocab_size,input_embedding_size])\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(embedding,encoder_inputs)\n",
    "    # 使用dynamic_rnn构建LSTM模型，将输入编码成隐层向量。\n",
    "    # encoder_outputs用于attention，batch_size*encoder_inputs_length*rnn_size,\n",
    "    # encoder_state用于decoder的初始化状态，batch_size*rnn_szie\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder_cell, encoder_inputs_embedded,\n",
    "                                                       sequence_length=encoder_inputs_length,\n",
    "                                                       dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义decoder 部分(训练阶段)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<tf.Tensor 'decoder/Identity:0' shape=(?, ?, 10) dtype=float32>\n",
      "\t<tf.Tensor 'minibatch/decoder_targets:0' shape=(?, ?) dtype=int32>\n",
      "\t<tf.Tensor 'decoder/decoder/transpose_1:0' shape=(?, ?) dtype=int32>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('decoder'):\n",
    "    decoder_cell = _create_rnn_cell()\n",
    "    \n",
    "    #定义decoder的初始状态\n",
    "    decoder_initial_state = encoder_state\n",
    "    \n",
    "    #定义output_layer\n",
    "    output_layer = tf.layers.Dense(vocab_size,kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "    \n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(embedding, decoder_inputs)\n",
    "    \n",
    "    # 训练阶段，使用TrainingHelper+BasicDecoder的组合，这一般是固定的，当然也可以自己定义Helper类，实现自己的功能\n",
    "    training_helper = seq2seq.TrainingHelper(inputs=decoder_inputs_embedded,\n",
    "                                                        sequence_length=decoder_inputs_length,\n",
    "                                                        time_major=False, name='training_helper')\n",
    "    training_decoder = seq2seq.BasicDecoder(cell=decoder_cell, helper=training_helper,\n",
    "                                                       initial_state=decoder_initial_state,\n",
    "                                                       output_layer=output_layer)\n",
    "    \n",
    "    # 调用dynamic_decode进行解码，decoder_outputs是一个namedtuple，里面包含两项(rnn_outputs, sample_id)\n",
    "    # rnn_output: [batch_size, decoder_targets_length, vocab_size]，保存decode每个时刻每个单词的概率，可以用来计算loss\n",
    "    # sample_id: [batch_size], tf.int32，保存最终的编码结果。可以表示最后的答案\n",
    "    max_target_sequence_length = tf.reduce_max(decoder_inputs_length, name='max_target_len')\n",
    "    decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder=training_decoder,\n",
    "                                                          impute_finished=True,\n",
    "                                                          maximum_iterations=max_target_sequence_length)\n",
    "    decoder_logits_train = tf.identity(decoder_outputs.rnn_output)\n",
    "    sample_id = decoder_outputs.sample_id\n",
    "    max_target_sequence_length = tf.reduce_max(decoder_inputs_length, name='max_target_len')\n",
    "    mask = tf.sequence_mask(decoder_inputs_length,max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "    print('\\t%s' % repr(decoder_logits_train))\n",
    "    print('\\t%s' % repr(decoder_targets))\n",
    "    print('\\t%s' % repr(sample_id))\n",
    "    loss = seq2seq.sequence_loss(logits=decoder_logits_train,targets=decoder_targets, weights=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义decoder 部分(测试阶段)\n",
    "![seq2seq-feed-previous](figure/beam_search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('decoder',reuse=True):\n",
    "    start_tokens = tf.ones([batch_size, ], tf.int32)*1  #[batch_size]  数值为1\n",
    "    encoder_state = nest.map_structure(lambda s: seq2seq.tile_batch(s, 3),\n",
    "                                                   encoder_state)\n",
    "    inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=decoder_cell, embedding=embedding,\n",
    "                                                                             start_tokens=start_tokens,\n",
    "                                                                             end_token=1,\n",
    "                                                                             initial_state=encoder_state,\n",
    "                                                                             beam_width=3,\n",
    "                                                                             output_layer=output_layer)\n",
    "    beam_decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder=inference_decoder,maximum_iterations=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[6 9 9 3 4 7 0 0]\n",
      "encoder_inputs_length:\n",
      "6\n",
      "decoder_inputs:\n",
      "[1 6 9 9 3 4 7 0 0]\n",
      "decoder_inputs_length:\n",
      "7\n",
      "decoder_targets:\n",
      "[6 9 9 3 4 7 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][0,:])\n",
    "print('encoder_inputs_length:')\n",
    "print(x[encoder_inputs_length][0])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][0,:])\n",
    "print('decoder_inputs_length:')\n",
    "print(x[decoder_inputs_length][0])\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.32762354612350464\n",
      "  sample 1:\n",
      "    input     > [2 8 9 4 6 3 5 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 8  8  8]\n",
      " [ 9  9  9]\n",
      " [ 4  4  4]\n",
      " [ 6  6  6]\n",
      " [ 3  5  9]\n",
      " [ 5  3  3]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [2 5 4 2 6 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 5  3  5]\n",
      " [ 4  4  2]\n",
      " [ 2  5  4]\n",
      " [ 6  9  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [5 8 3 0 0 0 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 8  3  2]\n",
      " [ 3  8  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 0.23138172924518585\n",
      "  sample 1:\n",
      "    input     > [4 9 2 0 0 0 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 9  9  9]\n",
      " [ 2  7  9]\n",
      " [ 1  2  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [7 7 6 5 2 4 9 3]\n",
      "    predicted > [[7 7 7]\n",
      " [7 7 7]\n",
      " [6 6 6]\n",
      " [5 5 2]\n",
      " [4 2 5]\n",
      " [2 4 9]\n",
      " [3 9 4]\n",
      " [9 3 5]\n",
      " [1 1 1]]\n",
      "  sample 3:\n",
      "    input     > [4 9 3 3 7 0 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 9  9  9]\n",
      " [ 3  3  3]\n",
      " [ 3  7  3]\n",
      " [ 7  3  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 0.21507926285266876\n",
      "  sample 1:\n",
      "    input     > [7 7 8 7 2 2 3]\n",
      "    predicted > [[7 7 7]\n",
      " [7 7 7]\n",
      " [8 8 8]\n",
      " [4 7 2]\n",
      " [7 2 7]\n",
      " [3 2 7]\n",
      " [2 3 5]\n",
      " [1 1 1]]\n",
      "  sample 2:\n",
      "    input     > [2 7 9 6 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 7  7  9]\n",
      " [ 9  6  7]\n",
      " [ 6  9  6]\n",
      " [ 1  9  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 8 2 0 0 0 0]\n",
      "    predicted > [[ 2  8  8]\n",
      " [ 8  2  8]\n",
      " [ 2  2  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.3271256387233734\n",
      "  sample 1:\n",
      "    input     > [2 9 9 3 9 8 5 0]\n",
      "    predicted > [[ 9  7  9]\n",
      " [ 2  8  2]\n",
      " [ 2  4  2]\n",
      " [ 3  5  7]\n",
      " [ 9  2  5]\n",
      " [ 9  9  9]\n",
      " [ 7  5  3]\n",
      " [ 1  1  9]\n",
      " [-1 -1  1]]\n",
      "  sample 2:\n",
      "    input     > [8 4 7 5 4 0 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 4  2  2]\n",
      " [ 7  7  7]\n",
      " [ 5  4  4]\n",
      " [ 4  6  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [4 6 9 8 8 7 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 6  9  9]\n",
      " [ 9  6  6]\n",
      " [ 8  8  8]\n",
      " [ 8  8  8]\n",
      " [ 7  3  6]\n",
      " [ 1  6  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.3914913535118103\n",
      "  sample 1:\n",
      "    input     > [3 5 5 9 0 0 0]\n",
      "    predicted > [[ 3  5  3]\n",
      " [ 5  3  5]\n",
      " [ 5  3  5]\n",
      " [ 9  9  7]\n",
      " [ 1  1  9]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [4 5 4 8 4 5 2]\n",
      "    predicted > [[4 4 4]\n",
      " [4 4 5]\n",
      " [5 5 4]\n",
      " [5 5 8]\n",
      " [8 8 4]\n",
      " [8 4 5]\n",
      " [4 8 2]\n",
      " [1 1 1]]\n",
      "  sample 3:\n",
      "    input     > [9 4 7 5 6 5 0]\n",
      "    predicted > [[ 9  5  5]\n",
      " [ 4  4  4]\n",
      " [ 7  7  7]\n",
      " [ 5  9  9]\n",
      " [ 6  7  9]\n",
      " [ 1  9  7]\n",
      " [-1  1  1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.2255089282989502\n",
      "  sample 1:\n",
      "    input     > [2 3 9 0 0 0 0 0]\n",
      "    predicted > [[ 2  8  2]\n",
      " [ 3  3  3]\n",
      " [ 9  2  7]\n",
      " [ 1  4  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [5 9 8 0 0 0 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 9  8  8]\n",
      " [ 8  9  9]\n",
      " [ 1  9  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [4 7 7 9 0 0 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 7  7  9]\n",
      " [ 7  9  7]\n",
      " [ 9  7  7]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 0.3723776340484619\n",
      "  sample 1:\n",
      "    input     > [8 2 6 8 6 0 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 2  2  4]\n",
      " [ 6  6  8]\n",
      " [ 8  8  5]\n",
      " [ 6  1  8]\n",
      " [ 1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [4 6 3 7 6 6 6 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 6  6  6]\n",
      " [ 3  3  3]\n",
      " [ 7  6  6]\n",
      " [ 6  7  7]\n",
      " [ 6  7  6]\n",
      " [ 1  6  9]\n",
      " [-1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [9 7 5 4 5 0 0 0]\n",
      "    predicted > [[ 9  9  9]\n",
      " [ 7  7  7]\n",
      " [ 5  2  2]\n",
      " [ 4  9  9]\n",
      " [ 5  5  5]\n",
      " [ 1  1  6]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.2460956871509552\n",
      "  sample 1:\n",
      "    input     > [2 6 2 0 0 0 0]\n",
      "    predicted > [[ 2  8  5]\n",
      " [ 6  2  8]\n",
      " [ 2  5  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [2 8 4 8 4 3 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 4  8  4]\n",
      " [ 8  4  8]\n",
      " [ 8  8  8]\n",
      " [ 8  4  2]\n",
      " [ 3  3  3]\n",
      " [ 1  1  8]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [3 6 2 8 3 6 5]\n",
      "    predicted > [[ 3  3  3]\n",
      " [ 6  6  6]\n",
      " [ 2  8  8]\n",
      " [ 8  3  2]\n",
      " [ 5  2  5]\n",
      " [ 3  5  3]\n",
      " [ 6  4  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.21721991896629333\n",
      "  sample 1:\n",
      "    input     > [2 4 7 5 3 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 4  7  7]\n",
      " [ 7  4  4]\n",
      " [ 5  5  5]\n",
      " [ 3  4  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [9 5 2 6 3 8 7]\n",
      "    predicted > [[5 5 5]\n",
      " [9 9 9]\n",
      " [8 8 8]\n",
      " [2 2 7]\n",
      " [7 7 5]\n",
      " [7 5 2]\n",
      " [5 7 2]\n",
      " [1 1 1]]\n",
      "  sample 3:\n",
      "    input     > [4 2 7 8 0 0 0]\n",
      "    predicted > [[ 4  2  8]\n",
      " [ 2  4  4]\n",
      " [ 8  7  7]\n",
      " [ 7  3  2]\n",
      " [ 1  1  4]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.2289828509092331\n",
      "  sample 1:\n",
      "    input     > [8 8 2 0 0 0 0]\n",
      "    predicted > [[ 8  8  2]\n",
      " [ 8  2  8]\n",
      " [ 2  8  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [9 8 4 0 0 0 0]\n",
      "    predicted > [[ 9  8  9]\n",
      " [ 8  9  9]\n",
      " [ 4  9  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 2 4 5 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 2  2  2]\n",
      " [ 4  9  9]\n",
      " [ 5  4  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.35617268085479736\n",
      "  sample 1:\n",
      "    input     > [6 9 2 4 0 0 0 0]\n",
      "    predicted > [[ 6  6  9]\n",
      " [ 9  9  6]\n",
      " [ 2  4  4]\n",
      " [ 4  2  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [3 7 8 8 5 7 2 0]\n",
      "    predicted > [[ 3  3  3]\n",
      " [ 7  7  8]\n",
      " [ 8  8  7]\n",
      " [ 8  8  7]\n",
      " [ 2  2  5]\n",
      " [ 7  7  2]\n",
      " [ 9  5  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 6 9 0 0 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 6  7  8]\n",
      " [ 9  6  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 0.44849294424057007\n",
      "  sample 1:\n",
      "    input     > [3 7 5 6 7 9 0 0]\n",
      "    predicted > [[ 3  3  3]\n",
      " [ 7  7  7]\n",
      " [ 6  5  6]\n",
      " [ 5  6  5]\n",
      " [ 9  7  7]\n",
      " [ 7  9  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [6 8 8 0 0 0 0 0]\n",
      "    predicted > [[ 8  6  8]\n",
      " [ 6  8  6]\n",
      " [ 6  8  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [7 6 6 7 2 6 3 2]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 7  7  7]\n",
      " [ 7  7  6]\n",
      " [ 7  7  7]\n",
      " [ 6  6  7]\n",
      " [ 2  2  2]\n",
      " [ 2  5  8]\n",
      " [ 6  8  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 0.16510817408561707\n",
      "  sample 1:\n",
      "    input     > [4 3 9 2 4 8 9]\n",
      "    predicted > [[4 4 4]\n",
      " [3 3 3]\n",
      " [5 5 9]\n",
      " [9 9 2]\n",
      " [7 9 4]\n",
      " [8 7 8]\n",
      " [4 2 6]\n",
      " [2 8 5]\n",
      " [1 1 1]]\n",
      "  sample 2:\n",
      "    input     > [4 2 5 0 0 0 0]\n",
      "    predicted > [[ 2  4  4]\n",
      " [ 4  2  2]\n",
      " [ 5  5  2]\n",
      " [ 1  1  6]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 6 2 9 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 6  6  8]\n",
      " [ 2  2  5]\n",
      " [ 9  7  6]\n",
      " [ 1  5  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 0.18280677497386932\n",
      "  sample 1:\n",
      "    input     > [9 4 9 0 0 0 0 0]\n",
      "    predicted > [[ 9  9  6]\n",
      " [ 4  9  9]\n",
      " [ 9  4  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [3 5 2 6 4 6 0 0]\n",
      "    predicted > [[ 3  3  5]\n",
      " [ 5  5  3]\n",
      " [ 6  6  7]\n",
      " [ 2  2  2]\n",
      " [ 4  2  6]\n",
      " [ 2  4  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [8 5 9 4 2 0 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 5  5  9]\n",
      " [ 9  9  5]\n",
      " [ 4  4  4]\n",
      " [ 2  8  3]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 2800\n",
      "  minibatch loss: 0.32199400663375854\n",
      "  sample 1:\n",
      "    input     > [7 2 6 3 6 0 0 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 2  2  3]\n",
      " [ 6  6  8]\n",
      " [ 3  6  4]\n",
      " [ 6  3  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [6 7 3 9 0 0 0 0]\n",
      "    predicted > [[ 7  6  7]\n",
      " [ 6  7  6]\n",
      " [ 1  3  8]\n",
      " [-1  9  3]\n",
      " [-1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [4 3 8 7 7 3 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 3  3  3]\n",
      " [ 8  8  8]\n",
      " [ 7  9  7]\n",
      " [ 7  7  3]\n",
      " [ 3  3  7]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.48668527603149414\n",
      "  sample 1:\n",
      "    input     > [3 7 2 2 4 0 0 0]\n",
      "    predicted > [[ 3  2  2]\n",
      " [ 7  7  7]\n",
      " [ 2  3  3]\n",
      " [ 2  3  3]\n",
      " [ 4  6  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [2 7 4 4 2 3 9 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 7  7  4]\n",
      " [ 4  4  7]\n",
      " [ 4  4  2]\n",
      " [ 2  2  7]\n",
      " [ 3  3  4]\n",
      " [ 9  4  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [5 5 8 4 3 7 6 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 5  5  5]\n",
      " [ 8  8  8]\n",
      " [ 4  4  4]\n",
      " [ 3  3  7]\n",
      " [ 7  9  3]\n",
      " [ 6  6  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 3200\n",
      "  minibatch loss: 0.2466438114643097\n",
      "  sample 1:\n",
      "    input     > [4 9 6 9 8 6 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 9  9  9]\n",
      " [ 6  8  6]\n",
      " [ 9  5  8]\n",
      " [ 8  6  9]\n",
      " [ 6  6  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [7 4 8 9 5 2 6]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 4  4  4]\n",
      " [ 8  8  8]\n",
      " [ 9  9  9]\n",
      " [ 5  5  5]\n",
      " [ 2  5  5]\n",
      " [ 6  2  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [8 3 4 4 8 5 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 3  3  7]\n",
      " [ 4  4  5]\n",
      " [ 4  4  3]\n",
      " [ 8  9  4]\n",
      " [ 5  6  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 3400\n",
      "  minibatch loss: 0.2961788773536682\n",
      "  sample 1:\n",
      "    input     > [4 3 8 0 0 0 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 3  3  7]\n",
      " [ 8  2  8]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [4 6 2 0 0 0 0 0]\n",
      "    predicted > [[ 4  6  4]\n",
      " [ 6  4  4]\n",
      " [ 2  2  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [7 6 5 9 7 8 3 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 6  6  6]\n",
      " [ 5  5  5]\n",
      " [ 8  9  8]\n",
      " [ 7  7  7]\n",
      " [ 9  8  9]\n",
      " [ 9  3  7]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 3600\n",
      "  minibatch loss: 0.3043099641799927\n",
      "  sample 1:\n",
      "    input     > [7 7 2 3 4 4 3 9]\n",
      "    predicted > [[7 7 7]\n",
      " [7 7 7]\n",
      " [2 2 2]\n",
      " [4 4 4]\n",
      " [3 3 3]\n",
      " [3 5 9]\n",
      " [9 7 3]\n",
      " [4 8 4]\n",
      " [1 1 1]]\n",
      "  sample 2:\n",
      "    input     > [7 2 5 9 0 0 0 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 2  5  8]\n",
      " [ 5  2  5]\n",
      " [ 9  9  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [6 3 5 0 0 0 0 0]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 3  3  3]\n",
      " [ 5  9  1]\n",
      " [ 1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 3800\n",
      "  minibatch loss: 0.26044222712516785\n",
      "  sample 1:\n",
      "    input     > [8 8 5 0 0 0 0 0]\n",
      "    predicted > [[ 8  8  2]\n",
      " [ 8  8  8]\n",
      " [ 5  2  7]\n",
      " [ 1  1  8]\n",
      " [-1 -1  6]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [6 6 8 2 9 0 0 0]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 6  6  8]\n",
      " [ 8  8  6]\n",
      " [ 2  8  4]\n",
      " [ 9  5  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [4 5 7 2 4 0 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 5  5  5]\n",
      " [ 7  7  7]\n",
      " [ 2  2  2]\n",
      " [ 4  2  2]\n",
      " [ 1  1  9]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss: 0.3985794484615326\n",
      "  sample 1:\n",
      "    input     > [9 5 9 0 0 0 0 0]\n",
      "    predicted > [[ 5  9  9]\n",
      " [ 9  9  5]\n",
      " [ 9  5  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [8 5 3 6 8 6 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 8  8  8]\n",
      " [ 8  8  8]\n",
      " [ 3  3  3]\n",
      " [ 6  6  6]\n",
      " [ 7  7  6]\n",
      " [ 1  3  1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 5 4 0 0 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 5  2  6]\n",
      " [ 4  6  4]\n",
      " [ 1  1  5]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 4200\n",
      "  minibatch loss: 0.29730188846588135\n",
      "  sample 1:\n",
      "    input     > [8 3 9 9 7 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 3  3  3]\n",
      " [ 9  9  9]\n",
      " [ 9  4  9]\n",
      " [ 7  9  9]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [5 6 7 6 5 8 2]\n",
      "    predicted > [[5 5 5]\n",
      " [6 6 6]\n",
      " [7 7 7]\n",
      " [6 6 6]\n",
      " [5 3 5]\n",
      " [8 8 8]\n",
      " [8 4 2]\n",
      " [1 1 1]]\n",
      "  sample 3:\n",
      "    input     > [7 7 3 2 8 0 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 7  7  7]\n",
      " [ 3  2  8]\n",
      " [ 2  3  3]\n",
      " [ 8  8  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 4400\n",
      "  minibatch loss: 0.35038599371910095\n",
      "  sample 1:\n",
      "    input     > [4 7 7 6 0 0 0 0]\n",
      "    predicted > [[ 4  4  7]\n",
      " [ 7  7  4]\n",
      " [ 7  6  4]\n",
      " [ 6  7  3]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [5 5 7 2 6 6 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 5  5  5]\n",
      " [ 9  7  7]\n",
      " [ 3  2  6]\n",
      " [ 6  6  2]\n",
      " [ 6  6  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [8 2 5 0 0 0 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 2  3  5]\n",
      " [ 5  2  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 4600\n",
      "  minibatch loss: 0.2776692807674408\n",
      "  sample 1:\n",
      "    input     > [7 8 9 9 0 0 0 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 8  8  8]\n",
      " [ 9  9  9]\n",
      " [ 9  8  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [3 5 9 5 2 6 5 0]\n",
      "    predicted > [[ 3  3  5]\n",
      " [ 5  5  3]\n",
      " [ 9  9  5]\n",
      " [ 5  5  7]\n",
      " [ 2  8  8]\n",
      " [ 6  5  2]\n",
      " [ 9  2  3]\n",
      " [ 1  1  9]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [6 3 7 9 5 2 0 0]\n",
      "    predicted > [[ 6  7  6]\n",
      " [ 3  6  3]\n",
      " [ 7  5  7]\n",
      " [ 9  3  9]\n",
      " [ 5  8  5]\n",
      " [ 2  3  3]\n",
      " [ 1  1  9]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 4800\n",
      "  minibatch loss: 0.24092251062393188\n",
      "  sample 1:\n",
      "    input     > [2 5 9 2 4 6 2 7]\n",
      "    predicted > [[2 2 2]\n",
      " [5 5 5]\n",
      " [9 4 9]\n",
      " [2 9 2]\n",
      " [4 2 2]\n",
      " [6 5 4]\n",
      " [2 8 6]\n",
      " [7 7 3]\n",
      " [1 1 1]]\n",
      "  sample 2:\n",
      "    input     > [8 3 2 9 5 4 0 0]\n",
      "    predicted > [[ 8  8  8]\n",
      " [ 3  3  3]\n",
      " [ 2  2  2]\n",
      " [ 9  5  9]\n",
      " [ 5  9  5]\n",
      " [ 4  2  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [7 6 4 2 2 0 0 0]\n",
      "    predicted > [[ 7  7  7]\n",
      " [ 6  4  8]\n",
      " [ 4  6  6]\n",
      " [ 2  2  4]\n",
      " [ 2  8  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss: 0.24987684190273285\n",
      "  sample 1:\n",
      "    input     > [2 8 4 2 2 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 2  8  8]\n",
      " [ 4  4  2]\n",
      " [ 8  2  4]\n",
      " [ 8  2  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [6 9 4 8 9 8 2 0]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 9  9  9]\n",
      " [ 4  4  4]\n",
      " [ 8  8  8]\n",
      " [ 9  9  9]\n",
      " [ 8  8  3]\n",
      " [ 2  2  8]\n",
      " [ 1  1  1]\n",
      " [ 1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [6 6 2 5 5 6 0 0]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 5  6  6]\n",
      " [ 6  5  5]\n",
      " [ 2  2  2]\n",
      " [ 6  2  2]\n",
      " [ 2  5  6]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 5200\n",
      "  minibatch loss: 0.2918197810649872\n",
      "  sample 1:\n",
      "    input     > [5 4 8 5 0 0 0 0]\n",
      "    predicted > [[ 5  3  5]\n",
      " [ 4  4  2]\n",
      " [ 8  5  6]\n",
      " [ 5  8  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [6 8 6 3 8 5 0 0]\n",
      "    predicted > [[ 8  6  6]\n",
      " [ 6  8  8]\n",
      " [ 6  6  6]\n",
      " [ 3  3  3]\n",
      " [ 6  8  6]\n",
      " [ 6  5  2]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [4 3 6 3 9 2 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 3  3  3]\n",
      " [ 6  6  6]\n",
      " [ 3  5  3]\n",
      " [ 9  7  9]\n",
      " [ 2  3  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 5400\n",
      "  minibatch loss: 0.15758396685123444\n",
      "  sample 1:\n",
      "    input     > [3 2 7 0 0 0 0 0]\n",
      "    predicted > [[ 3  3  3]\n",
      " [ 2  2  3]\n",
      " [ 7  3  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [2 7 6 3 0 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 7  7  1]\n",
      " [ 6  1 -1]\n",
      " [ 3 -1 -1]\n",
      " [ 1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [5 5 7 5 0 0 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 5  5  5]\n",
      " [ 7  7  9]\n",
      " [ 5  3  7]\n",
      " [ 1  1  3]\n",
      " [-1 -1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 5600\n",
      "  minibatch loss: 0.306735634803772\n",
      "  sample 1:\n",
      "    input     > [9 2 2 2 2 4 0 0]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 9  9  5]\n",
      " [ 2  2  2]\n",
      " [ 2  2  8]\n",
      " [ 2  5  9]\n",
      " [ 8  2  1]\n",
      " [ 1  8 -1]\n",
      " [-1  1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 2:\n",
      "    input     > [4 2 4 5 3 9 7 4]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 2  2  2]\n",
      " [ 4  4  9]\n",
      " [ 5  5  2]\n",
      " [ 7  3  6]\n",
      " [ 3  7  3]\n",
      " [ 9  9  4]\n",
      " [ 4  4  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [6 3 2 3 6 0 0 0]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 3  3  3]\n",
      " [ 4  2  3]\n",
      " [ 3  3  2]\n",
      " [ 2  6  7]\n",
      " [ 5  1  1]\n",
      " [ 1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 5800\n",
      "  minibatch loss: 0.4090876281261444\n",
      "  sample 1:\n",
      "    input     > [6 6 8 5 5 7 9 8]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 6  5  5]\n",
      " [ 8  6  6]\n",
      " [ 5  8  8]\n",
      " [ 5  8  8]\n",
      " [ 9  7  7]\n",
      " [ 7  7  7]\n",
      " [ 8  3  1]\n",
      " [ 1  1 -1]]\n",
      "  sample 2:\n",
      "    input     > [5 2 3 7 4 0 0 0]\n",
      "    predicted > [[ 5  5  5]\n",
      " [ 2  2  4]\n",
      " [ 3  3  3]\n",
      " [ 7  4  2]\n",
      " [ 4  7  7]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [2 8 4 4 8 0 0 0]\n",
      "    predicted > [[ 2  2  2]\n",
      " [ 8  4  8]\n",
      " [ 4  8  4]\n",
      " [ 4  8  8]\n",
      " [ 8  4  4]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss: 0.2645653188228607\n",
      "  sample 1:\n",
      "    input     > [6 2 8 4 2 2 8]\n",
      "    predicted > [[ 6  6  6]\n",
      " [ 5  2  2]\n",
      " [ 2  6  8]\n",
      " [ 8  2  2]\n",
      " [ 2  4  4]\n",
      " [ 4  5  2]\n",
      " [ 8  8  8]\n",
      " [ 1  8  1]\n",
      " [-1  1 -1]]\n",
      "  sample 2:\n",
      "    input     > [4 7 9 8 2 3 4]\n",
      "    predicted > [[ 4  4  4]\n",
      " [ 7  7  7]\n",
      " [ 9  9  9]\n",
      " [ 8  8  8]\n",
      " [ 2  2  2]\n",
      " [ 5  3  3]\n",
      " [ 3  4  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "  sample 3:\n",
      "    input     > [3 4 9 2 6 8 3]\n",
      "    predicted > [[ 3  3  3]\n",
      " [ 4  2  4]\n",
      " [ 9  9  9]\n",
      " [ 2  4  8]\n",
      " [ 6  6  2]\n",
      " [ 8  6  6]\n",
      " [ 3  3  5]\n",
      " [ 1  1  1]\n",
      " [-1 -1 -1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 6001\n",
    "batches_in_epoch = 200\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(beam_decoder_outputs.predicted_ids, fd)\n",
    "            #print(predict_)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs], predict_)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
